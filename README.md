# Charbot Project - Building a conversational agent using seq2seq models

### Motivation
#### - Gain deepened understanding on NLP and NLU
#### - Improve SW skills
#### - Improve programming skills in TensorFlow 2.x
#### - Training models on GCP
#### - Model deployment on GCP

### Progress
#### - Encoder-Decoder based seq2seq conversational agent with attentions.
#####	- Hands on experience with NMT using a seq2seq model with attention
#####	- Explore and preprocess Cornell movie-dialogs corpus dataset
#####	- Build encoder-decoder model with attention: Two-layered encoder with bidirectional GRU, two-layered decoder with general attention
#####	- Define customized training loop
#####	- Understand BLEU score, perplexity, and cross_entropy. Store training and testing metrics and losses in the training loop for later examination using TensorBoard

----- In progress -----
#####	- Train the model on GCP
#####	- Model deployment on GCP
##### - Intergrate it into the portfolio
