# Charbot Project - Building a conversational agent using seq2seq models

### Motivation
#### - Gain deepened understanding on NLP and NLU
#### - Improve SW development understanding: development + deployment
#### - Improve undestanding on TensorFlow 2.x
#### - Familiarize model training and deployment on GCP

### Steps
#### - Encoder-Decoder based seq2seq conversational agent with attentions.
#####	- Hands-on experience with NMT using a seq2seq model with attention
#####	- Explore and preprocess Cornell movie-dialogs corpus dataset
#####	- Build encoder-decoder model with attention: Single layer GRU for both encoder and decoder. Decoder with general attention
#####	- Define customized training loop
#####	- Understand BLEU score, perplexity, and cross_entropy. Store training and testing metrics and losses during training, monitor training via TensorBoard

				----- In progress -----

#####	- Training on GCP
#####	- Model deployment on GCP
